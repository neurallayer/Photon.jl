var documenterSearchIndex = {"docs":
[{"location":"metrics/#Metrics-1","page":"Metrics","title":"Metrics","text":"","category":"section"},{"location":"metrics/#","page":"Metrics","title":"Metrics","text":"Metrics can be passed to the Workout initializer and provide extra insights next to the loss value. Every metric is invoked with two parameters: predicted outcome and the labels.","category":"page"},{"location":"metrics/#","page":"Metrics","title":"Metrics","text":"BinaryAccuracy\nOneHotBinaryAccuracy\nSmartReducer","category":"page"},{"location":"metrics/#Photon.Metrics.BinaryAccuracy","page":"Metrics","title":"Photon.Metrics.BinaryAccuracy","text":"Binary accuracy calculation\n\n\n\n\n\n","category":"type"},{"location":"metrics/#Photon.Metrics.OneHotBinaryAccuracy","page":"Metrics","title":"Photon.Metrics.OneHotBinaryAccuracy","text":"Binary accuracy for a onehot classification.\n\n\n\n\n\n","category":"type"},{"location":"metrics/#Photon.Metrics.SmartReducer","page":"Metrics","title":"Photon.Metrics.SmartReducer","text":"Stores the calculated metrics. If multiple values are provided at the same step (like is the case with validation metrics), the moving average over those values will be stored.\n\n\n\n\n\n","category":"type"},{"location":"metrics/#Callbacks-1","page":"Metrics","title":"Callbacks","text":"","category":"section"},{"location":"metrics/#","page":"Metrics","title":"Metrics","text":"Callbacks can be passed to the train! function and provide a way to extend the functionality of Photon. Their functionality ranges from callbacks that generate output (like console or plots), to callbacks that save the model and callbacks that abort the training due to lack of progress.","category":"page"},{"location":"metrics/#","page":"Metrics","title":"Metrics","text":"Meter\nConsoleMeter\nSilentMeter\nFileMeter\nPlotMeter\nTensorBoardMeter\nEarlyStop\nAutoSave\nEpochSave","category":"page"},{"location":"metrics/#Photon.Callbacks.Meter","page":"Metrics","title":"Photon.Callbacks.Meter","text":"A meter is responsible for presenting metric values. It can be used just as a regular callback argument to the train! function. A meter is not limited to printing results to the console output, it can also be showing it on a TensorBoard or storing results in a database for example.\n\n\n\n\n\n","category":"type"},{"location":"metrics/#Photon.Callbacks.ConsoleMeter","page":"Metrics","title":"Photon.Callbacks.ConsoleMeter","text":"Logs metrics to the console output. By default it will only log at the end of an epoch and log the epoch, step, loss and validation loss. This is also the default configuration when you run train! without specifying oter callbacks.\n\nUsage\n\nmeter = ConsoleMeter([:loss, :val_accuracy, :accuracy]; epochOnly=false)\ntrain!(workout, data, val_data; epochs=5, cb=meter)\n\n\n\n\n\n","category":"type"},{"location":"metrics/#Photon.Callbacks.SilentMeter","page":"Metrics","title":"Photon.Callbacks.SilentMeter","text":"Use a SilentMeter in case no output is required. The default of train! function is to use a ConsoleMeter and using the SilentMeter this behavior can be overriden.\n\nUsage\n\ntrain!(workout, data, val_data; epochs=5, cb=SilentMeter())\n\n\n\n\n\n","category":"type"},{"location":"metrics/#Photon.Callbacks.FileMeter","page":"Metrics","title":"Photon.Callbacks.FileMeter","text":"Logs metrics to a delimeted text file. By default it will log the metrics loss and val_loss at the end of each training step and end of the validation phase.\n\n\n\n\n\n","category":"type"},{"location":"metrics/#Photon.Callbacks.PlotMeter","page":"Metrics","title":"Photon.Callbacks.PlotMeter","text":"Plot metrics using the Plots module. At the end of each epoch the plot will be updated with the values of the metrics. This works especially nice if you are prototyping some model in an IDE like Juno.\n\n\n\n\n\n","category":"type"},{"location":"metrics/#Photon.Callbacks.TensorBoardMeter","page":"Metrics","title":"Photon.Callbacks.TensorBoardMeter","text":"Logs metrics to a TensorBoard file so it can be viewed with TensorBoard. By default it will log the metrics loss and val_loss at the end of each training step and end of the validation phase.\n\nThis meter depends on the TensorBoardLogger to be installed. So if you didn't do so already, please run:\n\nimport Pkg; Pkg.add(\"TensorBoardLogger\")\n\n\n\n\n\n","category":"type"},{"location":"metrics/#Photon.Callbacks.EarlyStop","page":"Metrics","title":"Photon.Callbacks.EarlyStop","text":"Stop the training if a certain metric didn't improve\n\n\n\n\n\n","category":"type"},{"location":"metrics/#Photon.Callbacks.AutoSave","page":"Metrics","title":"Photon.Callbacks.AutoSave","text":"Save the Workout if a certain metric has improved since the last epoch\n\nUsage\n\n\n# save as long as the validation loss is declining\ntrain!(workout, data, cb=AutoSave(:val_loss))\n\n\n\n\n\n","category":"type"},{"location":"metrics/#Photon.Callbacks.EpochSave","page":"Metrics","title":"Photon.Callbacks.EpochSave","text":"Save the Workout at the end of every epoch. Optionally provide a filename.\n\nUsage\n\ntrain!(workout, data, cb=EpochSave())\n\n\n\n\n\n","category":"type"},{"location":"metrics/#Utils-1","page":"Metrics","title":"Utils","text":"","category":"section"},{"location":"metrics/#","page":"Metrics","title":"Metrics","text":"Photon comes with a number of utility functions for common tasks with regards to using metrics.","category":"page"},{"location":"metrics/#","page":"Metrics","title":"Metrics","text":"getmetricname\nhistory\nplotmetrics","category":"page"},{"location":"metrics/#Photon.Metrics.getmetricname","page":"Metrics","title":"Photon.Metrics.getmetricname","text":"Function to generate the fully qualified metric name. It uses the metric name and the phase (:train or :valid) to come up with a unique name.\n\ngetmetricname(:loss, :train) # return is :loss\ngetmetricname(:loss, :valid) # return is :val_loss\n\n\n\n\n\n","category":"function"},{"location":"metrics/#Photon.Metrics.history","page":"Metrics","title":"Photon.Metrics.history","text":"Get the history of a metric. The provided metric has the fully qualified name and the returned value is a tuple of steps and values.\n\nh = history(workout, :val_loss)\n# returns e.g ([1000, 2000, 3000, 4000], [0.81, 0.73, 0.64, 0.61])\n\nh = history(workout, :loss)\n\n\n\n\n\n","category":"function"},{"location":"metrics/#Photon.plotmetrics","page":"Metrics","title":"Photon.plotmetrics","text":"Plot the metrics after some training. This function will plot all the metrics in a single graph.\n\nIn order to avoid Photon being dependend on Plots, the calling code will have to provide that module as the first parameter.\n\nUsage\n\ntrain!(workout, mydata, epochs=10)\n\nimport Plots\nplotmetrics(Plots, workout)\n\n\n\n\n\n","category":"function"},{"location":"core/#Basic-1","page":"Core","title":"Basic","text":"","category":"section"},{"location":"core/#","page":"Core","title":"Core","text":"Workout\nsaveWorkout\nloadWorkout\nvalidate\npredict\ntrain!\nfreeze!\nunfreeze!\nstop\ngradients","category":"page"},{"location":"core/#Photon.Workout","page":"Core","title":"Photon.Workout","text":"The Workout keeps track of the progress of the training session. At least a model and a loss function needs to be provided. Optional an optimizer and one or more metrics can be specified.\n\nIf no optimizer is specified, SGD will be used. If no metrics are provided, only the loss during training and validation will be registered (:loss and :val_loss).\n\nThe provided mover will move data to the correct device. See also SmartMover. If no mover is required, you can provide the identity function instead.\n\nUsage\n\nworkout = Workout(model, L1Loss())\n\nworkout = Workout(model, CrossEntropy(), Adam())\n\nworkout = Workout(model, HingeLoss(); acc=BinaryAccuracy())\n\nworkout = Workout(model, L1Loss(), mover=identity)\n\n\n\n\n\n","category":"type"},{"location":"core/#Photon.saveWorkout","page":"Core","title":"Photon.saveWorkout","text":"Save a workout to a file. This will save all the state that is captured in the workout and enables to continue at a later stage using the loadWorkout function. Under the hood this function uses Julia serialization.\n\n\n\n\n\n","category":"function"},{"location":"core/#Photon.loadWorkout","page":"Core","title":"Photon.loadWorkout","text":"Load a workout from a file and return the initialized Workout.\n\nUsage\n\nworkout = loadWorkout(\"workout_1000.dat\")\ntrain!(workout, mydata)\n\n\n\n\n\n","category":"function"},{"location":"core/#Photon.validate","page":"Core","title":"Photon.validate","text":"Validate a minibatch and calculate the loss and metrics. Typically this function is called from the train! method. But if required can also be invoked directly.\n\n\n\n\n\n","category":"function"},{"location":"core/#Photon.predict","page":"Core","title":"Photon.predict","text":"Predict a sample, either a single value or a batch. Compared to invoking the model directory with model(x), predit takes care of:\n\nMoving the data to the GPU if required.\nShaping the data into a batch (controlled by makebatch parameter)\n\nUsage\n\nx = randn(Float32, 224, 224, 3)\npredict(workout, x)\n\n\n\n\n\n","category":"function"},{"location":"core/#Photon.train!","page":"Core","title":"Photon.train!","text":"Train the model based on a supervised dataset and for a number of epochs. train! can be called multiple times and will continue to train where is left of last time.\n\nBy default the train! function will try to ensure the data is of the right type (e.g. Float32) and on the right device (e.g. GPU) before feeding it to the model.\n\nUsage\n\ntrain!(workout, traindata)\ntrain!(workout, traindata, testdata, epochs=50)\n\n\n\n\n\n","category":"function"},{"location":"core/#Photon.freeze!","page":"Core","title":"Photon.freeze!","text":"Freeze a parameter so it no longer will be updated during training.\n\n\n\n\n\n","category":"function"},{"location":"core/#Photon.unfreeze!","page":"Core","title":"Photon.unfreeze!","text":"Unfreeze a parameter so it will be updated again during training.\n\n\n\n\n\n","category":"function"},{"location":"core/#Photon.stop","page":"Core","title":"Photon.stop","text":"Stop a training session. Typically invoked by a callback function that detects that the training is not progressing anymore.\n\nIf this function is called outside the scope of a trianing session, an exception is thrown.\n\n\n\n\n\n","category":"function"},{"location":"core/#Photon.gradients","page":"Core","title":"Photon.gradients","text":"Utility function to calculate the gradients. Useful when checking for vanishing or exploding gradients. The returned value is a Vector of (Param, Gradient).\n\n\n\n\n\n","category":"function"},{"location":"core/#Context-1","page":"Core","title":"Context","text":"","category":"section"},{"location":"core/#","page":"Core","title":"Core","text":"Context is a core concept in Photon. It determines what device (GPU or CPU) to use and what datatype (Float64/32/16) is required. Once the context is set, models and data will use this by default.","category":"page"},{"location":"core/#","page":"Core","title":"Core","text":"Context\ngetContext\nsetContext\nresetContext\nMover\nSmartMover","category":"page"},{"location":"core/#Photon.Context","page":"Core","title":"Photon.Context","text":"Context is used by various parts of Photon to determine what the device and datatype should be for data. It allows for quickly switches between GPU and CPU based environments.\n\nAttributes\n\ndevice::Symbol the type of device. For now supported :cpu and :gpu\ndeviceId::Int the id of the device, useful for example if you multiple GPU's\ndtype::Type the type you want to use for parameters. Most common are Float32, Float16 or Float64.\n\n\n\n\n\n","category":"type"},{"location":"core/#Photon.getContext","page":"Core","title":"Photon.getContext","text":"Get the currently configured Context.\n\n\n\n\n\n","category":"function"},{"location":"core/#Photon.setContext","page":"Core","title":"Photon.setContext","text":"Update the Context with the provided values. If values are no specified, the current value will be used.\n\n\n\n\n\n","category":"function"},{"location":"core/#Photon.resetContext","page":"Core","title":"Photon.resetContext","text":"Reset the Context to its default values. That means if there is a GPU detected GPU, otherwise CPU. And as a datatype Float32.\n\n\n\n\n\n","category":"function"},{"location":"core/#Photon.Mover","page":"Core","title":"Photon.Mover","text":"Moves data to the right device like a CPU or GPU. However implememetations can provide extra functionality like also taking care of the correct data types.\n\nThe default Mover used by Photon is SmartMover if no other mover is specified during instantiation of the Workout.\n\n\n\n\n\n","category":"type"},{"location":"core/#Photon.SmartMover","page":"Core","title":"Photon.SmartMover","text":"SmartMover converts data to the right device and optional data type for a model. It uses the context to determine the device (cpu or gpu) and datatype that the data needs to be.\n\nIt move_float is true, SmartMover will ensure that any provided Array of the type AbstractFloat will convert to the Float type as defined in the context.\n\nIt supports Tuples, Arrays and KnetArrays and a combination of those.\n\n\n\n\n\n","category":"type"},{"location":"core/#Internal-1","page":"Core","title":"Internal","text":"","category":"section"},{"location":"core/#","page":"Core","title":"Core","text":"You normally won't have to invoke the following functions directly when training a model. But in some cases you might want to write a specialized version of them.","category":"page"},{"location":"core/#","page":"Core","title":"Core","text":"Photon.back!\nPhoton.step!","category":"page"},{"location":"core/#Photon.back!","page":"Core","title":"Photon.back!","text":"Perform the back propagation and update of weights in a single go.\n\n\n\n\n\n","category":"function"},{"location":"core/#Photon.step!","page":"Core","title":"Photon.step!","text":"Take a single step in updating the weights of a model. This function will be invoked from train! to do the actual learning.\n\nFor a minibatch (x,y) of data, the folowing sequence will be executed:\n\nperform the forward pass\ncalculate the loss\nupdate and remember the metrics, if any\ndo the backpropagation and update the weights\n\n\n\n\n\n","category":"function"},{"location":"layers/#Basic-1","page":"Layers","title":"Basic","text":"","category":"section"},{"location":"layers/#","page":"Layers","title":"Layers","text":"Dense\nDropout\nBatchNorm\nFlatten","category":"page"},{"location":"layers/#Photon.Dense","page":"Layers","title":"Photon.Dense","text":"Regular densely-connected NN layer.\n\nDense implements the operation: output = activation(dot(input, weight) + bias) where activation is the element-wise activation function passed as the activation argument, weight is a weights matrix created by the layer, and bias is a bias vector created by the layer (only applicable if use_bias is true).\n\nUsage\n\nlayer = Dense(10, relu)\nlayer = Dense(100, use_bias=false)\n\n\n\n\n\n","category":"type"},{"location":"layers/#Photon.Dropout","page":"Layers","title":"Photon.Dropout","text":"Dropout layer with optional the rate (between 0 and 1) of dropout. If no rate is specified, 0.5 (so 50%) will be used.\n\n\n\n\n\n","category":"type"},{"location":"layers/#Photon.BatchNorm","page":"Layers","title":"Photon.BatchNorm","text":"Batch normalization layer (Ioffe and Szegedy, 2014). Normalizes the input at each batch, i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1.\n\nFinally, if activation is not nothing, it is applied to the outputs as well.\n\n\n\n\n\n","category":"type"},{"location":"layers/#Photon.Flatten","page":"Layers","title":"Photon.Flatten","text":"Flattening Layer. Photon by default already has flattening funcitonality build into the Dense layer, so you won't need to include a separate Flatten layer before a Dense layer.\n\n\n\n\n\n","category":"type"},{"location":"layers/#Container-1","page":"Layers","title":"Container","text":"","category":"section"},{"location":"layers/#","page":"Layers","title":"Layers","text":"Containers are special type of layers that contain other layers. They typically extend the abstract type that allows to use them as regular Vectors.","category":"page"},{"location":"layers/#","page":"Layers","title":"Layers","text":"StackedLayer\nSequential\nConcurrent\nResidual","category":"page"},{"location":"layers/#Photon.StackedLayer","page":"Layers","title":"Photon.StackedLayer","text":"Stacked layer is a abstract type and defines common behavior for containers layers that enables to access them as arrays.\n\n\n\n\n\n","category":"type"},{"location":"layers/#Photon.Sequential","page":"Layers","title":"Photon.Sequential","text":"Sequential layer allows to chain together a number of other layers.\n\nUsage\n\nmodel = Sequential(Conv2D(100),MaxPool(),Dense(10))\n\n\n\n\n\n","category":"type"},{"location":"layers/#Photon.Concurrent","page":"Layers","title":"Photon.Concurrent","text":"Concurrrent layer allows for stacking a number of other layers in parallel and combining their results before returning it.\n\nThis layer will stack on the second last dimension. So with 2D and 3D convolution this will be the channel layer (WxHxCxN). As a result other dimensions have to the same.\n\n\n\n\n\n","category":"type"},{"location":"layers/#Photon.Residual","page":"Layers","title":"Photon.Residual","text":"Residual Layer works like a Sequential layer, however before returning the result it will be combined with the orginal input (residual). This is a popular techique in modern neural networds since it allows for better backpropagation.\n\nThis will stack on the second last dimension. So with 2D and 3D convolution this will be the channel layer (WxHxCxN)\n\n\n\n\n\n","category":"type"},{"location":"layers/#Convolutional-1","page":"Layers","title":"Convolutional","text":"","category":"section"},{"location":"layers/#","page":"Layers","title":"Layers","text":"Photon contains convolutional layers for 2D and 3D spatial data.","category":"page"},{"location":"layers/#","page":"Layers","title":"Layers","text":"A 2D convolutional layer would require a 4D Array in the shape of WxHxCxN (width x height x channels x batch). So for a typical image classification problem this could look like: 224 x 224 x 3 x 8 (224 by 224 image, with 3 colors and 8 samples per batch).","category":"page"},{"location":"layers/#","page":"Layers","title":"Layers","text":"Conv2D\nConv2DTranspose\n\nConv3D\nConv3DTranspose","category":"page"},{"location":"layers/#Photon.Conv2D","page":"Layers","title":"Photon.Conv2D","text":"2D convolution layer (e.g. spatial convolution over images).\n\nThis layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. If use_bias is true, a bias vector is created and added to the outputs. Finally, if activation is not nothing, it is applied to the outputs as well.\n\n\n\n\n\n","category":"type"},{"location":"layers/#Photon.Conv2DTranspose","page":"Layers","title":"Photon.Conv2DTranspose","text":"Transposed 2D convolution layer (sometimes called Deconvolution).\n\nThe need for transposed convolutions generally arises from the desire to use a transformation going in the opposite direction of a normal convolution, i.e., from something that has the shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution.\n\n\n\n\n\n","category":"type"},{"location":"layers/#Photon.Conv3D","page":"Layers","title":"Photon.Conv3D","text":"3D convolution layer (e.g. spatial convolution over volumes).\n\nThis layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. If use_bias is true, a bias vector is created and added to the outputs. Finally, if activation is not nothing, it is applied to the outputs as well.\n\n\n\n\n\n","category":"type"},{"location":"layers/#Photon.Conv3DTranspose","page":"Layers","title":"Photon.Conv3DTranspose","text":"Transposed 3D convolution layer (sometimes called Deconvolution).\n\nThe need for transposed convolutions generally arises from the desire to use a transformation going in the opposite direction of a normal convolution, i.e., from something that has the shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution.\n\n\n\n\n\n","category":"type"},{"location":"layers/#Pooling-1","page":"Layers","title":"Pooling","text":"","category":"section"},{"location":"layers/#","page":"Layers","title":"Layers","text":"PoolingLayer\nMaxPool2D\nAvgPool2D\nMaxPool3D\nAvgPool3D\nAdaptiveAvgPool\nAdaptiveMaxPool","category":"page"},{"location":"layers/#Photon.PoolingLayer","page":"Layers","title":"Photon.PoolingLayer","text":"Pooling layers\n\n\n\n\n\n","category":"type"},{"location":"layers/#Photon.MaxPool2D","page":"Layers","title":"Photon.MaxPool2D","text":"Max pooling operation for two dimensional (spatial) data.\n\n\n\n\n\n","category":"type"},{"location":"layers/#Photon.AvgPool2D","page":"Layers","title":"Photon.AvgPool2D","text":"Average pooling operation for two dimensional (spatial) data.\n\n\n\n\n\n","category":"type"},{"location":"layers/#Photon.MaxPool3D","page":"Layers","title":"Photon.MaxPool3D","text":"Max pooling operation for three dimensional (spatial) data.\n\n\n\n\n\n","category":"type"},{"location":"layers/#Photon.AvgPool3D","page":"Layers","title":"Photon.AvgPool3D","text":"Average pooling operation for three dimensional (spatial) data.\n\n\n\n\n\n","category":"type"},{"location":"layers/#Photon.AdaptiveAvgPool","page":"Layers","title":"Photon.AdaptiveAvgPool","text":"Adaptive Average Pool has a fixed size output and enables creating a convolutional network that can be used for multiple image formats.\n\n\n\n\n\n","category":"type"},{"location":"layers/#Photon.AdaptiveMaxPool","page":"Layers","title":"Photon.AdaptiveMaxPool","text":"Adaptive MaxPool has a fixed size output and enables creating a convolutional network that can be used for different image sizes.\n\n\n\n\n\n","category":"type"},{"location":"layers/#Recurrent-1","page":"Layers","title":"Recurrent","text":"","category":"section"},{"location":"layers/#","page":"Layers","title":"Layers","text":"RNN\nLSTM\nGRU","category":"page"},{"location":"layers/#Photon.RNN","page":"Layers","title":"Photon.RNN","text":"Applies a multi-layer Elman RNN with :tanh or :relu non-linearity to an input sequence.\n\nFor each element in the input sequence, each layer computes the following function:\n\nh_t = texttanh(W_ih x_t + b_ih + W_hh h_(t-1) + b_hh)\n\n\n\n\n\n","category":"function"},{"location":"layers/#Photon.LSTM","page":"Layers","title":"Photon.LSTM","text":"Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence.\n\nFor each element in the input sequence, each layer computes the following function:\n\nbeginarrayll i_t = sigmoid(W_ii x_t + b_ii + W_hi h_(t-1) + b_hi) f_t = sigmoid(W_if x_t + b_if + W_hf h_(t-1) + b_hf) g_t = tanh(W_ig x_t + b_ig + W_hc h_(t-1) + b_hg) o_t = sigmoid(W_io x_t + b_io + W_ho h_(t-1) + b_ho) c_t = f_t * c_(t-1) + i_t * g_t h_t = o_t * tanh(c_t) endarray\n\nUsage\n\nlayer = LSTM(50)\nlayer = LSTM(50, 2, bidirectional=true)\n\n\n\n\n\n","category":"function"},{"location":"layers/#Photon.GRU","page":"Layers","title":"Photon.GRU","text":"Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.\n\nFor each element in the input sequence, each layer computes the following function:\n\nbeginarrayll r_t = sigma(W_ir x_t + b_ir + W_hr h_(t-1) + b_hr) z_t = sigma(W_iz x_t + b_iz + W_hz h_(t-1) + b_hz) n_t = tanh(W_in x_t + b_in + r_t * (W_hn h_(t-1)+ b_hn)) h_t = (1 - z_t) * n_t + z_t * h_(t-1) endarray\n\nUsage\n\nlayer = GRU(50)\nlayer = GRU(50, 2, bidirectional=true)\n\n\n\n\n\n","category":"function"},{"location":"layers/#Experimental-1","page":"Layers","title":"Experimental","text":"","category":"section"},{"location":"layers/#","page":"Layers","title":"Layers","text":"ContextSwitch","category":"page"},{"location":"layers/#Photon.ContextSwitch","page":"Layers","title":"Photon.ContextSwitch","text":"Beginning of allowing for a single model instance to run on multiple devices (expiremental)\n\n\n\n\n\n","category":"type"},{"location":"losses/#Loss-functions-1","page":"Losses","title":"Loss functions","text":"","category":"section"},{"location":"losses/#","page":"Losses","title":"Losses","text":"Loss functions can be used both to calculate the loss as the last step in a neural network as well as calculate metrics. In either cases they are provided as an argument to the Workout constructor","category":"page"},{"location":"losses/#","page":"Losses","title":"Losses","text":"# L1Loss as a loss\nworkout = Workout(model, L1Loss())\n\n# BCELoss as a loss function and FocalLoss as a metric\nworkout = Workout(model, BCELoss(), floss=FocalLoss())","category":"page"},{"location":"losses/#","page":"Losses","title":"Losses","text":"Loss\nL1Loss\nL2Loss\nLNLoss\nPseudoHuberLoss\nBCELoss\nCrossEntropyLoss\nHingeLoss\nSquaredHingeLoss\nFocalLoss","category":"page"},{"location":"losses/#Photon.Loss","page":"Losses","title":"Photon.Loss","text":"Abstract type for the loss functions. However Photon accepts any function as a loss function as long as it is callable and returns the loss value as a scalar type.\n\n\n\n\n\n","category":"type"},{"location":"losses/#Photon.L1Loss","page":"Losses","title":"Photon.L1Loss","text":"Calculates the mean absolute error between label and pred.\n\nL = sum_i vert label_i - pred_i vert\n\nlabel and pred can have arbitrary shape as long as they have the same number of elements.\n\n\n\n\n\n","category":"type"},{"location":"losses/#Photon.L2Loss","page":"Losses","title":"Photon.L2Loss","text":"Calculates the mean squared error between label and pred.\n\nL = frac12 sum_i (label_i - pred_i)^2\n\nlabel and pred can have arbitrary shape as long as they have the same number of elements.\n\n\n\n\n\n","category":"type"},{"location":"losses/#Photon.LNLoss","page":"Losses","title":"Photon.LNLoss","text":"More generic version of L1loss and L2loss that allows L{N}Loss.\n\nL = frac12 sum_i vert label_i - pred_i vert^N\n\nlabel and pred can have arbitrary shape as long as they have the same number of elements.\n\n\n\n\n\n","category":"type"},{"location":"losses/#Photon.PseudoHuberLoss","page":"Losses","title":"Photon.PseudoHuberLoss","text":"Pseudo Huber Loss implementation, somewhere between a L1 and L2 loss.\n\n\n\n\n\n","category":"type"},{"location":"losses/#Photon.BCELoss","page":"Losses","title":"Photon.BCELoss","text":"BCE (Binary Cross Entropy) loss is useful when training logistic regression.\n\nL = - sum_i label_i * log(pred_i) +             (1 - label_i) * log(1 - pred_i)\n\nIf use_sigmoid is true, first a sigmoid activation will be applied before calcuating the BCE loss.\n\n\n\n\n\n","category":"type"},{"location":"losses/#Photon.CrossEntropyLoss","page":"Losses","title":"Photon.CrossEntropyLoss","text":"CrossEntropy loss function with support for an optional weight parameter. The weight parameter can be static (for example to handle class inbalances) or dynamic, so passed every time when the lost function is invoked.\n\nCross Entropy Function:\n\nL = - sum_i label_i log(output_i)\n\nIf use_softmax is true, first the softmax(output) will be performed before cross entropy.\n\nUsage\n\nworkout = Workout(model, CrossEntropyLoss(), SGD())\n\n\n\n\n\n","category":"type"},{"location":"losses/#Photon.HingeLoss","page":"Losses","title":"Photon.HingeLoss","text":"Calculates the hinge loss function often used in SVMs:\n\nL = sum_i max(0 margin - pred_i cdot label_i)\n\nwhere pred is the classifier prediction and label is the target tensor containing values -1 or 1. label and pred must have the same number of elements.\n\nIf autofix is true, will convert label from {0,1} to {-1,1}\n\n\n\n\n\n","category":"type"},{"location":"losses/#Photon.SquaredHingeLoss","page":"Losses","title":"Photon.SquaredHingeLoss","text":"Calculates the soft-margin loss function used in SVMs:\n\nL = sum_i max(0 margin - pred_i cdot label_i)^2\n\nwhere pred is the classifier prediction and label is the target tensor containing values -1 or 1. label and pred can have arbitrary shape as long as they have the same number of elements.\n\n\n\n\n\n","category":"type"},{"location":"losses/#Photon.FocalLoss","page":"Losses","title":"Photon.FocalLoss","text":"Focal loss for multi-classification\n\nL=-alpha(1-p_t)^gammaln(p_t)\n\nSee also Focal Loss for Dense Object Detection     https://arxiv.org/abs/1708.02002\n\n\n\n\n\n","category":"type"},{"location":"data/#Datasets-1","page":"Data","title":"Datasets","text":"","category":"section"},{"location":"data/#","page":"Data","title":"Data","text":"Dataset\nImageDataset\nJLDDataset\nDFDataset\nJuliaDBDataset\nVectorDataset\nTestDataset","category":"page"},{"location":"data/#Photon.Data.Dataset","page":"Data","title":"Photon.Data.Dataset","text":"Datasets can load and transform data and can be used in a pipeline. Typically they would have length and index methods implemented and need to return only a single sample. The MiniBatch transformer would collect these single samples and put them into a mini batch.\n\ndata = SomeDataset() |> SomeTransformer() |> MiniBatch()\ntrain!(workout, data)\n\nPlease note that in case all your data would fit in memory, you can feed it directly to the train! function (so a dataset is not required)\n\nX = [randn(10,10,16) for i in 1:100]\nY = [randn(1,16) for i in 1:100]\ntrain!(workout, zip(X,Y))\n\n\n\n\n\n","category":"type"},{"location":"data/#Photon.Data.ImageDataset","page":"Data","title":"Photon.Data.ImageDataset","text":"Dataset that loads an single image from a file and optionally resizes the image. The labels are passed as is.\n\nUsage\n\nds = ImageDataset(filenames, labels, resize=(200,200))\n\n\n\n\n\n","category":"type"},{"location":"data/#Photon.Data.JLDDataset","page":"Data","title":"Photon.Data.JLDDataset","text":"Dataset that loads data from a JLD(2) file. The format that is stored is expected to be in the shape of: (X,Y)\n\nNote: Tested with JLD2 library only.\n\nExample:\n\nusing JLD2\n\njldopen(\"example.jld2\", \"w\") do file\n    file[\"image1\"] = (randn(Float32,28,28,1), rand(0:9,1))\n    file[\"image2\"] = (randn(Float32,28,28,1), rand(0:9,1))\nend\n\nf = jldopen(\"example.jld2\", \"r\")\nds = JLD2Dataset(f)\nds[1]\n\n\n\n\n\n","category":"type"},{"location":"data/#Photon.Data.DFDataset","page":"Data","title":"Photon.Data.DFDataset","text":"Dataset that retrieves is data from a dataframe. The provided column names for X and Y can be either a single Symbol or a Vector of Symbols.\n\nUsage\n\ndf = DataFrame(randn(4,20))\nds = DFDataset(df, :x1, :x2)\nds = DFDataset(df, [:x1, :x3], [:x2,:x4])\n\n\n\n\n\n","category":"type"},{"location":"data/#Photon.Data.VectorDataset","page":"Data","title":"Photon.Data.VectorDataset","text":"Dataset that contains two vectors, one for the input data and one for the labels.\n\n\n\n\n\n","category":"type"},{"location":"data/#Photon.Data.TestDataset","page":"Data","title":"Photon.Data.TestDataset","text":"A dataset that contains random generated samples. Ideal for quick testing of a model. The random values will be drawn from a normal distribution.\n\nYou need to provide the shape of X, Y and the number of samples that the dataset should contain. Optionally you can specify a sleep value to simulate IO blocking.\n\nUsage\n\nxshape = (28,28,1)\nyshape = (10,)\nds = TestDataset(xshape, yshape, 60000)\n\nds = TestDataset((100,), (1,), 1000, sleep=0.1)\n\n\n\n\n\n","category":"type"},{"location":"data/#Transformers-1","page":"Data","title":"Transformers","text":"","category":"section"},{"location":"data/#","page":"Data","title":"Data","text":"Transformer\nImageCrop\nNormalizer\nOneHotEncoder\nSubset\nNoisingTransfomer\nMiniBatch\nSplit","category":"page"},{"location":"data/#Photon.Data.Transformer","page":"Data","title":"Photon.Data.Transformer","text":"Transformers enable you to transform the output generated by a datasets. Many of the transformers can be chained together.\n\ndata = SomeDataset(...)\ndata = data |> Transformer1(...) |> Transformer2(...) |> Transformer3(...)\n\ntrain!(workout, data)\n\n\n\n\n\n","category":"type"},{"location":"data/#Photon.Data.ImageCrop","page":"Data","title":"Photon.Data.ImageCrop","text":"Randomly crop an image in the shape of WxHxC to a certain size. This Transformer uses plain Array operations and doesn't rely on packages like Images.jl\n\nUsage\n\n# Only crop X\nds = TestDataset((100,100,3),(10,),100)\nds = ds |> ImageCrop((50,50))\n\n\n# Crop both X and Y\nds = TestDataset((100,100,3),(50,50,3),100)\nds = ds |> ImageCrop((50,50), (20,20))\n\n\n\n\n\n","category":"type"},{"location":"data/#Photon.Data.Normalizer","page":"Data","title":"Photon.Data.Normalizer","text":"Normalize data before feeding it to a model. A typical usecase is to normalize an image.  By default will only normalize to the input data (:X) and not the labels (:Y).\n\nUsage\n\nds = TestDataset((28,28,1),(10,),100) |> Normalize()\n\n\n\n\n\n","category":"type"},{"location":"data/#Photon.Data.OneHotEncoder","page":"Data","title":"Photon.Data.OneHotEncoder","text":"OneHot transformer for a single sample. Uses the onehot function to perform the actual transoformation.\n\nSupports both single and multi class encoding:\n\n5 => [0,0,0,0,0,1,0,0,0,0]\n[5,7] => [0,0,0,0,0,1,0,1,0,0]\n\nUsage\n\nds = mnistds() |> OneHotEncoder(0:9)\n\n\n\n\n\n","category":"type"},{"location":"data/#Photon.Data.Subset","page":"Data","title":"Photon.Data.Subset","text":"Return a subset of samples of the underlying dataset. Optionally you can specify a start index (default = 1).\n\nUsage\n\ndata = MyDataset() |> Subset(1:100)\n\n\n\n\n\n","category":"type"},{"location":"data/#Photon.Data.NoisingTransfomer","page":"Data","title":"Photon.Data.NoisingTransfomer","text":"Add noise to the samples in a dataset. By default will only add noise to the input data (:X) and not the labels (:Y).\n\nUsage\n\nds = TestDataset((28,28,1),(10,),100)\nds = ds |> NoiseTransformer(noiselevel=0.05)\n\n\n\n\n\n","category":"type"},{"location":"data/#Photon.Data.MiniBatch","page":"Data","title":"Photon.Data.MiniBatch","text":"A MiniBatch is a transformer that will collect multiple samples from the underlying dataset and put it in a minibatch. So it will call a dataset to get a single sample and combines them into a minibatch. The MiniBatch itself is an iterator.\n\nIt will do this using threading, so when a dataset will read some samples from disk this won't become a botttleneck.\n\nUsage\n\ndata = ImageDataset(filenames,labels) |> MiniBatch(16, shuffle=False)\ntrain!(workout, data)\n\n\n\n\n\n","category":"type"},{"location":"data/#Photon.Data.Split","page":"Data","title":"Photon.Data.Split","text":"Split one dataset into two subsets, one for training and one for validation. By default Split will shuffle the indexes first in order to get a representative validaiton set. The default split is 80% for training and 20% for validation.\n\nUsage\n\ndata_train, data_valid = ImageDataset(...) |> Split(0.25, shuffle=false)\n\n\n\n\n\n","category":"type"},{"location":"community/#Community-1","page":"Community","title":"Community","text":"","category":"section"},{"location":"community/#","page":"Community","title":"Community","text":"All Photon users are welcome to ask questions on the Julia forum. Of course issues can be opened on Github where you also can get the source code.","category":"page"},{"location":"#Introduction-1","page":"Get Started","title":"Introduction","text":"","category":"section"},{"location":"#","page":"Get Started","title":"Get Started","text":"Photon is a developer friendly framework for Machine Learning in Julia. Under the hood it leverages Knet and it provides a Keras like API on top of that.","category":"page"},{"location":"#Installation-1","page":"Get Started","title":"Installation","text":"","category":"section"},{"location":"#","page":"Get Started","title":"Get Started","text":"Since Photon is improving rapidly, the package can be best installed with the Julia package manager directly from the Github repository.","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"From the Julia REPL, type ] to enter the Pkg REPL mode and run:","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"pkg> add https://github.com/neurallayer/Photon.jl","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"Once a stable API is in place, it will be possible to use:","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"pkg> add Photon","category":"page"},{"location":"#Steps-1","page":"Get Started","title":"Steps","text":"","category":"section"},{"location":"#","page":"Get Started","title":"Get Started","text":"To train your own model, there are four steps to follow:","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"Create your model using the layers that come out of the box with Photon or using your own custom layers.\nCreate a workout that combines the model, a loss function and an optimiser. Optionally you can also add some metrics that you want to monitor during the progress of the training.\nPrepare your data with Data pipelines.\nTrain the model by calling train! on the workout and the training data.","category":"page"},{"location":"#Step-1:-Create-a-Model-1","page":"Get Started","title":"Step 1: Create a Model","text":"","category":"section"},{"location":"#","page":"Get Started","title":"Get Started","text":"A model can use out of the box layers or your own layers. Photon support most common type of layer:","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"Dense or fully connected layers\n2D ad 3D convolutional layers\nDifferent type of Pooling layers\nRecurrent layers (RNN, LSTM, GRU)\nDropout and Batch Normalization layers\nSeveral types of container layers like Sequential and Residual","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"Some examples how to create the different type of network architectures:","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"mymodel = Sequential(\n            Dense(64, relu),\n            Dense(10)\n)","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"mymodel = Sequential(\n            Conv2D(64, 3, relu),\n            Conv2D(64, 3, relu),\n            MaxPool(),\n            Dense(10)\n)","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"mymodel = Sequential(\n            LSTM(64),\n            Dense(64),\n            Dense(10)\n)","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"So normally you won't need to create your own layers. But if you have to, a layer is in it simplest form nothing more than function that receives and Array and returns an Array. So the following could be a layer ;)","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"myLayer(X) = is_full_moon() ? X .- 1 : X","category":"page"},{"location":"#Step-2:-Define-a-Workout-1","page":"Get Started","title":"Step 2: Define a Workout","text":"","category":"section"},{"location":"#","page":"Get Started","title":"Get Started","text":"A workout combines a model + loss + optimiser and keeps track of the progress during the actual training. The workout is stateful in the sense that you can run multiple training sessions (train!) and the progress will be recorded appropriately.   ","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"The minimum required code to create a workout is:","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"workout = Workout(mymodel, MSELoss())","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"This will create a workout that will use the default optimiser (SGD) and only the loss metric being tracked.","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"Alternatively you can pass an optimiser and define the metrics that you want to get tracked during the training sessions. Photon tracks :loss and :val_loss (for the validation phase) by default, but you can define additional ones.","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"workout = Workout(mymodel, MSE(), SGD(), acc=BinaryAccuracy())","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"Each additional metric is added as an optional parameter, where the name of the parameter (so acc in the above example) will be the metricname and the function the metric calculation.","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"Another useful feature is that a Workout can saved and restored at any moment during the training. And not only the model and its parameters will be saved. Also the state of the optimiser and any of the logged metrics will be saved and restored to their previous state. This makes it also possible to shared workout with colleagues (although they still need to have the same packages installed installed as you).","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"filename = saveWorkout(workout)\n\nworkout2 = loadWorkout(filename)","category":"page"},{"location":"#Step-3:-Prepare-the-Data-1","page":"Get Started","title":"Step 3: Prepare the Data","text":"","category":"section"},{"location":"#","page":"Get Started","title":"Get Started","text":"Although Photon is perfectly happy to accept plain Vectors as data, this often won't be feasible due to the data not fitting into memory. In those cases you can use the data pipeline feature of Photon.","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"A typical pipeline would look something like this:","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"  data = SomeDataset(source) |> SomeTransformers() |> MiniBatch()","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"Add then the pipeline can be used directly in the training cycle:","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"  train!(workout, data)","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"Photon comes out the box with several reusable components for creating these pipelines. They can be divided into two types; Datasets that are the start of a pipeline and retrieve the data from some source and Transformers that transform the output of a previous step in the pipeline.","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"Source datasets","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"ImageDataset\nTestDataset\nArrayDataset\nJLDDataset","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"Transformers","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"Normalizer\nCropper\nMiniBatch\nNoiser\nSplit","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"A complete pipeline for image data could look something like this:","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"data = ImageDataset(files, labels, resize=(250,250))\ndata = data |> Crop(200,200) |> Normalize() |> MiniBatch(8)","category":"page"},{"location":"#Step-4:-Run-the-Training-1","page":"Get Started","title":"Step 4: Run the Training","text":"","category":"section"},{"location":"#","page":"Get Started","title":"Get Started","text":"The final step is the actual training and is done by invoking the train! function with the right parameters.","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"train!(workout, data, epochs=5)","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"You always need to provide a workout and the data for training. Other parameters are optional.","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"So for example the validation phase is optional. But if you provide data for the validation phase, Photon will automatically run the validation step after each training epoch.","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"train!(workout, data, training_data, epochs=10)","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"Any additional defined metrics and the loss value will then be available both for training and validation.","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"The data is expected to be a tuple of (X, Y) where X and Y can be tuples again in case your model expects multiple inputs or outputs. So some examples of valid formats","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"(X,Y)\n((X1,X2), Y)\n(X, (Y1, Y2, Y3))\n((X1, X2), (Y1, Y2))","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"By default train! will convert each batch to the right data type and device. This is controlled by the optional parameter convertor. If you don't want a conversion to take place and ensured the provided data is already in the right format, you can pass the identity function:","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"train!(workout, data; convertor=identity)","category":"page"}]
}
