var documenterSearchIndex = {"docs":
[{"location":"metrics/#Metrics-1","page":"Metrics","title":"Metrics","text":"","category":"section"},{"location":"metrics/#","page":"Metrics","title":"Metrics","text":"Metrics can be passed to the Workout initializer and provide extra insights next to the loss value. Every metric is invoked with two parameters: predicted outcome and the labels.","category":"page"},{"location":"metrics/#","page":"Metrics","title":"Metrics","text":"BinaryAccuracy\nOneHotBinaryAccuracy\nSmartReducer","category":"page"},{"location":"metrics/#Callbacks-1","page":"Metrics","title":"Callbacks","text":"","category":"section"},{"location":"metrics/#","page":"Metrics","title":"Metrics","text":"Callbacks can be passed to the train! function and provide a way to extend the functionality of Photon. Their functionality ranges from callbacks that generate output (like console or plots), to callbacks that save the model and callbacks that abort the training due to lack of progress.","category":"page"},{"location":"metrics/#","page":"Metrics","title":"Metrics","text":"Meter\nConsoleMeter\nSilentMeter\nFileMeter\nPlotMeter\nTensorBoardMeter\nEarlyStop\nAutoSave\nEpochSave","category":"page"},{"location":"metrics/#Utils-1","page":"Metrics","title":"Utils","text":"","category":"section"},{"location":"metrics/#","page":"Metrics","title":"Metrics","text":"Photon comes with a number of utility functions for common tasks with regards to using metrics.","category":"page"},{"location":"metrics/#","page":"Metrics","title":"Metrics","text":"getmetricname\nhistory\nplotmetrics","category":"page"},{"location":"core/#Basic-1","page":"Core","title":"Basic","text":"","category":"section"},{"location":"core/#","page":"Core","title":"Core","text":"Workout\nsaveWorkout\nloadWorkout\nvalidate\npredict\ntrain!\nfreeze!\nunfreeze!\nstop\ngradients","category":"page"},{"location":"core/#Photon.Workout","page":"Core","title":"Photon.Workout","text":"The Workout keeps track of the progress of the training session. At least a model and a loss function needs to be provided. Optional an optimizer and one or more metrics can be specified.\n\nIf no optimizer is specified, SGD will be used. If no metrics are provided, only the loss during training and validation will be registered (:loss and :val_loss).\n\nThe provided mover will move data to the correct device. See also SmartMover. If no mover is required, you can provide the identity function instead.\n\nUsage\n\nworkout = Workout(model, L1Loss())\n\nworkout = Workout(model, CrossEntropy(), Adam())\n\nworkout = Workout(model, HingeLoss(); acc=BinaryAccuracy())\n\nworkout = Workout(model, L1Loss(), mover=identity)\n\n\n\n\n\n","category":"type"},{"location":"core/#Photon.validate","page":"Core","title":"Photon.validate","text":"Validate a minibatch and calculate the loss and metrics. Typically this function is called from the train! method. But if required can also be invoked directly.\n\n\n\n\n\n","category":"function"},{"location":"core/#Photon.predict","page":"Core","title":"Photon.predict","text":"Predict a sample, either a single value or a batch. Compared to invoking the model directory with model(x), predit takes care of:\n\nMoving the data to the GPU if required.\nShaping the data into a batch (controlled by makebatch parameter)\n\nUsage\n\nx = randn(Float32, 224, 224, 3)\npredict(workout, x)\n\n\n\n\n\n","category":"function"},{"location":"core/#Photon.train!","page":"Core","title":"Photon.train!","text":"Train the model based on a supervised dataset and for a number of epochs. train! can be called multiple times and will continue to train where is left of last time.\n\nBy default the train! function will try to ensure the data is of the right type (e.g. Float32) and on the right device (e.g. GPU) before feeding it to the model.\n\nUsage\n\ntrain!(workout, traindata)\ntrain!(workout, traindata, testdata, epochs=50)\n\n\n\n\n\n","category":"function"},{"location":"core/#Photon.freeze!","page":"Core","title":"Photon.freeze!","text":"Freeze a parameter so it no longer will be updated during training.\n\n\n\n\n\n","category":"function"},{"location":"core/#Photon.unfreeze!","page":"Core","title":"Photon.unfreeze!","text":"Unfreeze a parameter so it will be updated again during training.\n\n\n\n\n\n","category":"function"},{"location":"core/#Photon.stop","page":"Core","title":"Photon.stop","text":"Stop a training session. Typically invoked by a callback function that detects that the training is not progressing anymore.\n\nIf this function is called outside the scope of a trianing session, an exception is thrown.\n\n\n\n\n\n","category":"function"},{"location":"core/#Photon.gradients","page":"Core","title":"Photon.gradients","text":"Utility function to calculate the gradients. Useful when checking for vanishing or exploding gradients. The returned value is a Vector of (Param, Gradient).\n\n\n\n\n\n","category":"function"},{"location":"core/#Internal-1","page":"Core","title":"Internal","text":"","category":"section"},{"location":"core/#","page":"Core","title":"Core","text":"You normally won't have to invoke the following functions directly when training a model. But in some cases you might want to write a specialized version of them.","category":"page"},{"location":"core/#","page":"Core","title":"Core","text":"Photon.back!\nPhoton.step!","category":"page"},{"location":"core/#Photon.back!","page":"Core","title":"Photon.back!","text":"Perform the back propagation and update of weights in a single go.\n\n\n\n\n\n","category":"function"},{"location":"core/#Photon.step!","page":"Core","title":"Photon.step!","text":"Take a single step in updating the weights of a model. This function will be invoked from train! to do the actual learning.\n\nFor a minibatch (x,y) of data, the folowing sequence will be executed:\n\nperform the forward pass\ncalculate the loss\nupdate and remember the metrics, if any\ndo the backpropagation and update the weights\n\n\n\n\n\n","category":"function"},{"location":"layers/#Basic-1","page":"Layers","title":"Basic","text":"","category":"section"},{"location":"layers/#","page":"Layers","title":"Layers","text":"Dense\nDropout\nBatchNorm\nFlatten","category":"page"},{"location":"layers/#Container-1","page":"Layers","title":"Container","text":"","category":"section"},{"location":"layers/#","page":"Layers","title":"Layers","text":"Containers are special type of layers that contain other layers. They typically extend the abstract type that allows to use them as regular Vectors.","category":"page"},{"location":"layers/#","page":"Layers","title":"Layers","text":"StackedLayer\nSequential\nConcurrent\nResidual","category":"page"},{"location":"layers/#Convolutional-1","page":"Layers","title":"Convolutional","text":"","category":"section"},{"location":"layers/#","page":"Layers","title":"Layers","text":"Photon contains convolutional layers for 2D and 3D spatial data.","category":"page"},{"location":"layers/#","page":"Layers","title":"Layers","text":"A 2D convolutional layer would require a 4D Array in the shape of WxHxCxN (width x height x channels x batch). So for a typical image classification problem this could look like: 224 x 224 x 3 x 8 (224 by 224 image, with 3 colors and 8 samples per batch).","category":"page"},{"location":"layers/#","page":"Layers","title":"Layers","text":"Conv2D\nConv2DTranspose\n\nConv3D\nConv3DTranspose","category":"page"},{"location":"layers/#Pooling-1","page":"Layers","title":"Pooling","text":"","category":"section"},{"location":"layers/#","page":"Layers","title":"Layers","text":"PoolingLayer\nMaxPool2D\nAvgPool2D\nMaxPool3D\nAvgPool3D\nAdaptiveAvgPool\nAdaptiveMaxPool","category":"page"},{"location":"layers/#Recurrent-1","page":"Layers","title":"Recurrent","text":"","category":"section"},{"location":"layers/#","page":"Layers","title":"Layers","text":"RNN\nLSTM\nGRU","category":"page"},{"location":"layers/#Experimental-1","page":"Layers","title":"Experimental","text":"","category":"section"},{"location":"layers/#","page":"Layers","title":"Layers","text":"ContextSwitch","category":"page"},{"location":"losses/#Loss-functions-1","page":"Losses","title":"Loss functions","text":"","category":"section"},{"location":"losses/#","page":"Losses","title":"Losses","text":"Loss functions can be used both to calculate the loss as the last step in a neural network as well as calculate metrics. In either cases they are provided as an argument to the Workout constructor","category":"page"},{"location":"losses/#","page":"Losses","title":"Losses","text":"# L1Loss as a loss\nworkout = Workout(model, L1Loss())\n\n# BCELoss as a loss function and FocalLoss as a metric\nworkout = Workout(model, BCELoss(), floss=FocalLoss())","category":"page"},{"location":"losses/#","page":"Losses","title":"Losses","text":"Loss\nL1Loss\nL2Loss\nLNLoss\nPseudoHuberLoss\nBCELoss\nCrossEntropyLoss\nHingeLoss\nSquaredHingeLoss\nFocalLoss","category":"page"},{"location":"losses/#Photon.Losses.Loss","page":"Losses","title":"Photon.Losses.Loss","text":"Abstract type for the loss functions. However Photon accepts any function as a loss function as long as it is callable and returns the loss value as a scalar type.\n\n\n\n\n\n","category":"type"},{"location":"data/#Datasets-1","page":"Data","title":"Datasets","text":"","category":"section"},{"location":"data/#","page":"Data","title":"Data","text":"Dataset\nImageDataset\nJLDDataset\nDFDataset\nJuliaDBDataset\nVectorDataset\nTestDataset","category":"page"},{"location":"data/#Transformers-1","page":"Data","title":"Transformers","text":"","category":"section"},{"location":"data/#","page":"Data","title":"Data","text":"Transformer\nImageCrop\nNormalizer\nOneHotEncoder\nSubset\nNoisingTransfomer\nMiniBatch\nSplit","category":"page"},{"location":"community/#Community-1","page":"Community","title":"Community","text":"","category":"section"},{"location":"community/#","page":"Community","title":"Community","text":"All Photon users are welcome to ask questions on the Julia forum. Of course issues can be opened on Github where you also can get the source code.","category":"page"},{"location":"#Introduction-1","page":"Get Started","title":"Introduction","text":"","category":"section"},{"location":"#","page":"Get Started","title":"Get Started","text":"Photon is a developer friendly framework for Machine Learning in Julia. Under the hood it leverages Knet and it provides a Keras like API on top of that.","category":"page"},{"location":"#Installation-1","page":"Get Started","title":"Installation","text":"","category":"section"},{"location":"#","page":"Get Started","title":"Get Started","text":"Since Photon is improving rapidly, the package can be best installed with the Julia package manager directly from the Github repository.","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"From the Julia REPL, type ] to enter the Pkg REPL mode and run:","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"pkg> add https://github.com/neurallayer/Photon.jl","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"Once a stable API is in place, it will be possible to use:","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"pkg> add Photon","category":"page"},{"location":"#Steps-1","page":"Get Started","title":"Steps","text":"","category":"section"},{"location":"#","page":"Get Started","title":"Get Started","text":"To train your own model, there are four steps to follow:","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"Create your model using the layers that come out of the box with Photon or using your own custom layers.\nCreate a workout that combines the model, a loss function and an optimiser. Optionally you can also add some metrics that you want to monitor during the progress of the training.\nPrepare your data with Data pipelines.\nTrain the model by calling train! on the workout and the training data.","category":"page"},{"location":"#Step-1:-Create-a-Model-1","page":"Get Started","title":"Step 1: Create a Model","text":"","category":"section"},{"location":"#","page":"Get Started","title":"Get Started","text":"A model can use out of the box layers or your own layers. Photon support most common type of layer:","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"Dense or fully connected layers\n2D ad 3D convolutional layers\nDifferent type of Pooling layers\nRecurrent layers (RNN, LSTM, GRU)\nDropout and Batch Normalization layers\nSeveral types of container layers like Sequential and Residual","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"Some examples how to create the different type of network architectures:","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"mymodel = Sequential(\n            Dense(64, relu),\n            Dense(10)\n)","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"mymodel = Sequential(\n            Conv2D(64, 3, relu),\n            Conv2D(64, 3, relu),\n            MaxPool(),\n            Dense(10)\n)","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"mymodel = Sequential(\n            LSTM(64),\n            Dense(64),\n            Dense(10)\n)","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"So normally you won't need to create your own layers. But if you have to, a layer is in it simplest form nothing more than function that receives and Array and returns an Array. So the following could be a layer ;)","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"myLayer(X) = is_full_moon() ? X .- 1 : X","category":"page"},{"location":"#Step-2:-Define-a-Workout-1","page":"Get Started","title":"Step 2: Define a Workout","text":"","category":"section"},{"location":"#","page":"Get Started","title":"Get Started","text":"A workout combines a model + loss + optimiser and keeps track of the progress during the actual training. The workout is stateful in the sense that you can run multiple training sessions (train!) and the progress will be recorded appropriately.   ","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"The minimum required code to create a workout is:","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"workout = Workout(mymodel, MSELoss())","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"This will create a workout that will use the default optimiser (SGD) and only the loss metric being tracked.","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"Alternatively you can pass an optimiser and define the metrics that you want to get tracked during the training sessions. Photon tracks :loss and :val_loss (for the validation phase) by default, but you can define additional ones.","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"workout = Workout(mymodel, MSE(), SGD(), acc=BinaryAccuracy())","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"Each additional metric is added as an optional parameter, where the name of the parameter (so acc in the above example) will be the metricname and the function the metric calculation.","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"Another useful feature is that a Workout can saved and restored at any moment during the training. And not only the model and its parameters will be saved. Also the state of the optimiser and any of the logged metrics will be saved and restored to their previous state. This makes it also possible to shared workout with colleagues (although they still need to have the same packages installed installed as you).","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"filename = saveWorkout(workout)\n\nworkout2 = loadWorkout(filename)","category":"page"},{"location":"#Step-3:-Prepare-the-Data-1","page":"Get Started","title":"Step 3: Prepare the Data","text":"","category":"section"},{"location":"#","page":"Get Started","title":"Get Started","text":"Although Photon is perfectly happy to accept plain Vectors as data, this often won't be feasible due to the data not fitting into memory. In those cases you can use the data pipeline feature of Photon.","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"A typical pipeline would look something like this:","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"  data = SomeDataset(source) |> SomeTransformers() |> MiniBatch()","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"Add then the pipeline can be used directly in the training cycle:","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"  train!(workout, data)","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"Photon comes out the box with several reusable components for creating these pipelines. They can be divided into two types; Datasets that are the start of a pipeline and retrieve the data from some source and Transformers that transform the output of a previous step in the pipeline.","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"Source datasets","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"ImageDataset\nTestDataset\nArrayDataset\nJLDDataset","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"Transformers","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"Normalizer\nCropper\nMiniBatch\nNoiser\nSplit","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"A complete pipeline for image data could look something like this:","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"data = ImageDataset(files, labels, resize=(250,250))\ndata = data |> Crop(200,200) |> Normalize() |> MiniBatch(8)","category":"page"},{"location":"#Step-4:-Run-the-Training-1","page":"Get Started","title":"Step 4: Run the Training","text":"","category":"section"},{"location":"#","page":"Get Started","title":"Get Started","text":"The final step is the actual training and is done by invoking the train! function with the right parameters.","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"train!(workout, data, epochs=5)","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"You always need to provide a workout and the data for training. Other parameters are optional.","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"So for example the validation phase is optional. But if you provide data for the validation phase, Photon will automatically run the validation step after each training epoch.","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"train!(workout, data, training_data, epochs=10)","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"Any additional defined metrics and the loss value will then be available both for training and validation.","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"The data is expected to be a tuple of (X, Y) where X and Y can be tuples again in case your model expects multiple inputs or outputs. So some examples of valid formats","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"(X,Y)\n((X1,X2), Y)\n(X, (Y1, Y2, Y3))\n((X1, X2), (Y1, Y2))","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"By default train! will convert each batch to the right data type and device. This is controlled by the optional parameter convertor. If you don't want a conversion to take place and ensured the provided data is already in the right format, you can pass the identity function:","category":"page"},{"location":"#","page":"Get Started","title":"Get Started","text":"train!(workout, data; convertor=identity)","category":"page"}]
}
