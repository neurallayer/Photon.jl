<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Layers · Photon</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><a href="../"><img class="logo" src="../assets/logo.png" alt="Photon logo"/></a><h1>Photon</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Get Started</a></li><li><span class="toctext">API</span><ul><li><a class="toctext" href="../core/">Core</a></li><li class="current"><a class="toctext" href>Layers</a><ul class="internal"><li><a class="toctext" href="#Basic-1">Basic</a></li><li><a class="toctext" href="#Container-1">Container</a></li><li><a class="toctext" href="#Convolutional-1">Convolutional</a></li><li><a class="toctext" href="#Pooling-1">Pooling</a></li><li><a class="toctext" href="#Recurrent-1">Recurrent</a></li><li><a class="toctext" href="#Experimental-1">Experimental</a></li></ul></li><li><a class="toctext" href="../losses/">Losses</a></li><li><a class="toctext" href="../metrics/">Metrics</a></li><li><a class="toctext" href="../data/">Data</a></li></ul></li><li><a class="toctext" href="../community/">Community</a></li></ul></nav><article id="docs"><header><nav><ul><li>API</li><li><a href>Layers</a></li></ul><a class="edit-page" href="https://github.com/neurallayer/Photon.jl/blob/master/docs/src/layers.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Layers</span><a class="fa fa-bars" href="#"></a></div></header><h2><a class="nav-anchor" id="Basic-1" href="#Basic-1">Basic</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Dense" href="#Photon.Dense"><code>Photon.Dense</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Regular densely-connected NN layer.</p><p>Dense implements the operation: output = activation(dot(input, weight) + bias) where activation is the element-wise activation function passed as the activation argument, weight is a weights matrix created by the layer, and bias is a bias vector created by the layer (only applicable if use_bias is true).</p><p><strong>Usage</strong></p><pre><code class="language-julia">layer = Dense(10, relu)
layer = Dense(100, use_bias=false)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/cc1dccb3f5d35306562ee42fd6df6a55d0af028d/src/layers/core.jl#L52-L67">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Dropout" href="#Photon.Dropout"><code>Photon.Dropout</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Dropout layer with optional the rate (between 0 and 1) of dropout. If no rate is specified, 0.5 (so 50%) will be used.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/cc1dccb3f5d35306562ee42fd6df6a55d0af028d/src/layers/core.jl#L136-L139">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.BatchNorm" href="#Photon.BatchNorm"><code>Photon.BatchNorm</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Batch normalization layer (Ioffe and Szegedy, 2014). Normalizes the input at each batch, i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1.</p><p>Finally, if activation is not nothing, it is applied to the outputs as well.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/cc1dccb3f5d35306562ee42fd6df6a55d0af028d/src/layers/core.jl#L154-L160">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Flatten" href="#Photon.Flatten"><code>Photon.Flatten</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Flattening Layer. Photon by default already has flattening funcitonality build into the Dense layer, so you won&#39;t need to include a separate Flatten layer before a Dense layer.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/cc1dccb3f5d35306562ee42fd6df6a55d0af028d/src/layers/core.jl#L111-L115">source</a></section><h2><a class="nav-anchor" id="Container-1" href="#Container-1">Container</a></h2><p>Containers are special type of layers that contain other layers. They typically extend the abstract type that allows to use them as regular Vectors.</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.StackedLayer" href="#Photon.StackedLayer"><code>Photon.StackedLayer</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Stacked layer is a abstract type and defines common behavior for containers layers that enables to access them as arrays.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/cc1dccb3f5d35306562ee42fd6df6a55d0af028d/src/layers/container.jl#L4-L7">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Sequential" href="#Photon.Sequential"><code>Photon.Sequential</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Sequential layer allows to chain together a number of other layers.</p><p><strong>Usage</strong></p><pre><code class="language-julia">model = Sequential(Conv2D(100),MaxPool(),Dense(10))</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/cc1dccb3f5d35306562ee42fd6df6a55d0af028d/src/layers/container.jl#L17-L26">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Concurrent" href="#Photon.Concurrent"><code>Photon.Concurrent</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Concurrrent layer allows for stacking a number of other layers in parallel and combining their results before returning it.</p><p>This layer will stack on the second last dimension. So with 2D and 3D convolution this will be the channel layer (WxHxCxN). As a result other dimensions have to the same.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/cc1dccb3f5d35306562ee42fd6df6a55d0af028d/src/layers/container.jl#L41-L48">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Residual" href="#Photon.Residual"><code>Photon.Residual</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Residual Layer works like a Sequential layer, however before returning the result it will be combined with the orginal input (residual). This is a popular techique in modern neural networds since it allows for better backpropagation.</p><p>This will stack on the second last dimension. So with 2D and 3D convolution this will be the channel layer (WxHxCxN)</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/cc1dccb3f5d35306562ee42fd6df6a55d0af028d/src/layers/container.jl#L64-L71">source</a></section><h2><a class="nav-anchor" id="Convolutional-1" href="#Convolutional-1">Convolutional</a></h2><p>Photon contains convolutional layers for 2D and 3D spatial data.</p><p>A 2D convolutional layer would require a 4D Array in the shape of WxHxCxN (width x height x channels x batch). So for a typical image classification problem this could look like: 224 x 224 x 3 x 8 (224 by 224 image, with 3 colors and 8 samples per batch).</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Conv2D" href="#Photon.Conv2D"><code>Photon.Conv2D</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>2D convolution layer (e.g. spatial convolution over images).</p><p>This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. If use_bias is true, a bias vector is created and added to the outputs. Finally, if activation is not nothing, it is applied to the outputs as well.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/cc1dccb3f5d35306562ee42fd6df6a55d0af028d/src/layers/conv.jl#L108-L115">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Conv2DTranspose" href="#Photon.Conv2DTranspose"><code>Photon.Conv2DTranspose</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Transposed 2D convolution layer (sometimes called Deconvolution).</p><p>The need for transposed convolutions generally arises from the desire to use a transformation going in the opposite direction of a normal convolution, i.e., from something that has the shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/cc1dccb3f5d35306562ee42fd6df6a55d0af028d/src/layers/conv.jl#L200-L208">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Conv3D" href="#Photon.Conv3D"><code>Photon.Conv3D</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>3D convolution layer (e.g. spatial convolution over volumes).</p><p>This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. If use_bias is true, a bias vector is created and added to the outputs. Finally, if activation is not nothing, it is applied to the outputs as well.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/cc1dccb3f5d35306562ee42fd6df6a55d0af028d/src/layers/conv.jl#L119-L126">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Conv3DTranspose" href="#Photon.Conv3DTranspose"><code>Photon.Conv3DTranspose</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Transposed 3D convolution layer (sometimes called Deconvolution).</p><p>The need for transposed convolutions generally arises from the desire to use a transformation going in the opposite direction of a normal convolution, i.e., from something that has the shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/cc1dccb3f5d35306562ee42fd6df6a55d0af028d/src/layers/conv.jl#L211-L219">source</a></section><h2><a class="nav-anchor" id="Pooling-1" href="#Pooling-1">Pooling</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.PoolingLayer" href="#Photon.PoolingLayer"><code>Photon.PoolingLayer</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Pooling layers</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/cc1dccb3f5d35306562ee42fd6df6a55d0af028d/src/layers/conv.jl#L223-L225">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.MaxPool2D" href="#Photon.MaxPool2D"><code>Photon.MaxPool2D</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Max pooling operation for two dimensional (spatial) data.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/cc1dccb3f5d35306562ee42fd6df6a55d0af028d/src/layers/conv.jl#L300">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.AvgPool2D" href="#Photon.AvgPool2D"><code>Photon.AvgPool2D</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Average pooling operation for two dimensional (spatial) data.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/cc1dccb3f5d35306562ee42fd6df6a55d0af028d/src/layers/conv.jl#L250">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.MaxPool3D" href="#Photon.MaxPool3D"><code>Photon.MaxPool3D</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Max pooling operation for three dimensional (spatial) data.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/cc1dccb3f5d35306562ee42fd6df6a55d0af028d/src/layers/conv.jl#L303">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.AvgPool3D" href="#Photon.AvgPool3D"><code>Photon.AvgPool3D</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Average pooling operation for three dimensional (spatial) data.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/cc1dccb3f5d35306562ee42fd6df6a55d0af028d/src/layers/conv.jl#L253">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.AdaptiveAvgPool" href="#Photon.AdaptiveAvgPool"><code>Photon.AdaptiveAvgPool</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Adaptive Average Pool has a fixed size output and enables creating a convolutional network that can be used for multiple image formats.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/cc1dccb3f5d35306562ee42fd6df6a55d0af028d/src/layers/conv.jl#L256-L259">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.AdaptiveMaxPool" href="#Photon.AdaptiveMaxPool"><code>Photon.AdaptiveMaxPool</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Adaptive MaxPool has a fixed size output and enables creating a convolutional network that can be used for different image sizes.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/cc1dccb3f5d35306562ee42fd6df6a55d0af028d/src/layers/conv.jl#L306-L309">source</a></section><h2><a class="nav-anchor" id="Recurrent-1" href="#Recurrent-1">Recurrent</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.RNN" href="#Photon.RNN"><code>Photon.RNN</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Applies a multi-layer Elman RNN with :tanh or :relu non-linearity to an input sequence.</p><p>For each element in the input sequence, each layer computes the following function:</p><p><span>$h_t = \text{tanh}(W_{ih} x_t + b_{ih} + W_{hh} h_{(t-1)} + b_{hh})$</span></p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/cc1dccb3f5d35306562ee42fd6df6a55d0af028d/src/layers/recurrent.jl#L67-L76">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.LSTM" href="#Photon.LSTM"><code>Photon.LSTM</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence.</p><p>For each element in the input sequence, each layer computes the following function:</p><p><span>$\begin{array}{ll} i_t = sigmoid(W_{ii} x_t + b_{ii} + W_{hi} h_{(t-1)} + b_{hi}) \\f_t = sigmoid(W_{if} x_t + b_{if} + W_{hf} h_{(t-1)} + b_{hf}) \\g_t = \tanh(W_{ig} x_t + b_{ig} + W_{hc} h_{(t-1)} + b_{hg}) \\o_t = sigmoid(W_{io} x_t + b_{io} + W_{ho} h_{(t-1)} + b_{ho}) \\c_t = f_t * c_{(t-1)} + i_t * g_t \\h_t = o_t * \tanh(c_t) \end{array}$</span></p><p><strong>Usage</strong></p><pre><code class="language-julia">layer = LSTM(50)
layer = LSTM(50, 2, bidirectional=true)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/cc1dccb3f5d35306562ee42fd6df6a55d0af028d/src/layers/recurrent.jl#L94-L116">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.GRU" href="#Photon.GRU"><code>Photon.GRU</code></a> — <span class="docstring-category">Function</span>.</div><div><div><p>Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.</p><p>For each element in the input sequence, each layer computes the following function:</p><p><span>$\begin{array}{ll} r_t = \sigma(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\z_t = \sigma(W_{iz} x_t + b_{iz} + W_{hz} h_{(t-1)} + b_{hz}) \\n_t = \tanh(W_{in} x_t + b_{in} + r_t * (W_{hn} h_{(t-1)}+ b_{hn})) \\h_t = (1 - z_t) * n_t + z_t * h_{(t-1)} \end{array}$</span></p><p><strong>Usage</strong></p><pre><code class="language-julia">layer = GRU(50)
layer = GRU(50, 2, bidirectional=true)</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/cc1dccb3f5d35306562ee42fd6df6a55d0af028d/src/layers/recurrent.jl#L132-L152">source</a></section><h2><a class="nav-anchor" id="Experimental-1" href="#Experimental-1">Experimental</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.ContextSwitch" href="#Photon.ContextSwitch"><code>Photon.ContextSwitch</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Beginning of allowing for a single model instance to run on multiple devices (expiremental)</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/cc1dccb3f5d35306562ee42fd6df6a55d0af028d/src/layers/core.jl#L175-L178">source</a></section><footer><hr/><a class="previous" href="../core/"><span class="direction">Previous</span><span class="title">Core</span></a><a class="next" href="../losses/"><span class="direction">Next</span><span class="title">Losses</span></a></footer></article></body></html>
