<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Losses · Photon</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><a href="../"><img class="logo" src="../assets/logo.png" alt="Photon logo"/></a><h1>Photon</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Get Started</a></li><li><span class="toctext">API</span><ul><li><a class="toctext" href="../core/">Core</a></li><li><a class="toctext" href="../layers/">Layers</a></li><li class="current"><a class="toctext" href>Losses</a><ul class="internal"><li><a class="toctext" href="#Loss-functions-1">Loss functions</a></li></ul></li><li><a class="toctext" href="../metrics/">Metrics</a></li><li><a class="toctext" href="../data/">Data</a></li></ul></li><li><a class="toctext" href="../community/">Community</a></li></ul></nav><article id="docs"><header><nav><ul><li>API</li><li><a href>Losses</a></li></ul><a class="edit-page" href="https://github.com/neurallayer/Photon.jl/blob/master/docs/src/losses.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Losses</span><a class="fa fa-bars" href="#"></a></div></header><h2><a class="nav-anchor" id="Loss-functions-1" href="#Loss-functions-1">Loss functions</a></h2><p>Loss functions can be used both to calculate the loss as the last step in a neural network as well as calculate metrics. In either cases they are provided as an argument to the Workout constructor</p><pre><code class="language-julia"># L1Loss as a loss
workout = Workout(model, L1Loss())

# BCELoss as a loss function and FocalLoss as a metric
workout = Workout(model, BCELoss(), floss=FocalLoss())</code></pre><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.Loss" href="#Photon.Loss"><code>Photon.Loss</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Abstract type for the loss functions. However Photon accepts any function as a loss function as long as it is callable and returns the loss value as a scalar type.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/69300c4aa684178a2cd9c64d4650be7290613685/src/core.jl#L13-L17">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.L1Loss" href="#Photon.L1Loss"><code>Photon.L1Loss</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Calculates the mean absolute error between <code>label</code> and <code>pred</code>.</p><p><span>$L = \sum_i \vert {label}_i - {pred}_i \vert$</span></p><p><code>label</code> and <code>pred</code> can have arbitrary shape as long as they have the same number of elements.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/69300c4aa684178a2cd9c64d4650be7290613685/src/losses.jl#L6-L13">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.L2Loss" href="#Photon.L2Loss"><code>Photon.L2Loss</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Calculates the mean squared error between <code>label</code> and <code>pred</code>.</p><p><span>$L = \frac{1}{2} \sum_i ({label}_i - {pred}_i)^2$</span></p><p><code>label</code> and <code>pred</code> can have arbitrary shape as long as they have the same number of elements.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/69300c4aa684178a2cd9c64d4650be7290613685/src/losses.jl#L28-L35">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.LNLoss" href="#Photon.LNLoss"><code>Photon.LNLoss</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>More generic version of L1loss and L2loss that allows L{N}Loss.</p><p><span>$L = \frac{1}{2} \sum_i \vert {label}_i - {pred}_i \vert^{N}$</span></p><p><code>label</code> and <code>pred</code> can have arbitrary shape as long as they have the same number of elements.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/69300c4aa684178a2cd9c64d4650be7290613685/src/losses.jl#L50-L58">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.PseudoHuberLoss" href="#Photon.PseudoHuberLoss"><code>Photon.PseudoHuberLoss</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Pseudo Huber Loss implementation, somewhere between a L1 and L2 loss.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/69300c4aa684178a2cd9c64d4650be7290613685/src/losses.jl#L71-L73">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.BCELoss" href="#Photon.BCELoss"><code>Photon.BCELoss</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>BCE (Binary Cross Entropy) loss is useful when training logistic regression.</p><p><span>$L = - \sum_i {label}_i * \log({pred}_i) +             (1 - {label}_i) * \log(1 - {pred}_i)$</span></p><p>If <code>use_sigmoid</code> is true, first a sigmoid activation will be applied before calcuating the BCE loss.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/69300c4aa684178a2cd9c64d4650be7290613685/src/losses.jl#L88-L96">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.CrossEntropyLoss" href="#Photon.CrossEntropyLoss"><code>Photon.CrossEntropyLoss</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>CrossEntropy loss function with support for an optional weight parameter. The weight parameter can be static (for example to handle class inbalances) or dynamic, so passed every time when the lost function is invoked.</p><p>Cross Entropy Function:</p><p><span>$L = - \sum_i {label}_i \log({output}_i)$</span></p><p>If use_softmax is true, first the softmax(output) will be performed before cross entropy.</p><p><strong>Usage</strong></p><pre><code class="language-julia">workout = Workout(model, CrossEntropyLoss(), SGD())</code></pre></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/69300c4aa684178a2cd9c64d4650be7290613685/src/losses.jl#L112-L130">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.HingeLoss" href="#Photon.HingeLoss"><code>Photon.HingeLoss</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Calculates the hinge loss function often used in SVMs:</p><p><span>$L = \sum_i max(0, {margin} - {pred}_i \cdot {label}_i)$</span></p><p>where <code>pred</code> is the classifier prediction and <code>label</code> is the target tensor containing values -1 or 1. <code>label</code> and <code>pred</code> must have the same number of elements.</p><p>If autofix is true, will convert label from {0,1} to {-1,1}</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/69300c4aa684178a2cd9c64d4650be7290613685/src/losses.jl#L150-L161">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.SquaredHingeLoss" href="#Photon.SquaredHingeLoss"><code>Photon.SquaredHingeLoss</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Calculates the soft-margin loss function used in SVMs:</p><p><span>$L = \sum_i max(0, {margin} - {pred}_i \cdot {label}_i)^2$</span></p><p>where <code>pred</code> is the classifier prediction and <code>label</code> is the target tensor containing values -1 or 1. <code>label</code> and <code>pred</code> can have arbitrary shape as long as they have the same number of elements.</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/69300c4aa684178a2cd9c64d4650be7290613685/src/losses.jl#L183-L192">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Photon.FocalLoss" href="#Photon.FocalLoss"><code>Photon.FocalLoss</code></a> — <span class="docstring-category">Type</span>.</div><div><div><p>Focal loss for multi-classification</p><p><span>$L=-alpha(1-p_t)^{gamma}ln(p_t)$</span></p><p>See also Focal Loss for Dense Object Detection     https://arxiv.org/abs/1708.02002</p></div></div><a class="source-link" target="_blank" href="https://github.com/neurallayer/Photon.jl/blob/69300c4aa684178a2cd9c64d4650be7290613685/src/losses.jl#L215-L222">source</a></section><footer><hr/><a class="previous" href="../layers/"><span class="direction">Previous</span><span class="title">Layers</span></a><a class="next" href="../metrics/"><span class="direction">Next</span><span class="title">Metrics</span></a></footer></article></body></html>
